1) optimize llm inference (all features, instead of one by one)
2) feature RSA
3) multivariate/factorial/interaction
4) Write up
5) publish on Github

Project plan:

part 1: SAE training 
part 2: Feature examination & distributions, clamping 
costs. 
	--I attempted to use the local LLM to 'feature identify' and 'clamp' but found it very inconsistent versus a large production model (Claude 3.7)
	-- reproduce some basic components of Anthropics intrepretability approach although I ended up limiting due to API costs (such as rubric scoring each individual prompt)

part 3: Cognitive Neuroscience approach (stimulus-response mapping, using designed stimuli, examining single feature)
	-- univariate contrast
	-- RSA approach
part 4: Feature examination of ID'd features

part 5: Multivariate stimulus-response mapping (designed stimuli)
part 6: Feature examination of ID'd features

part 7: monosemantic, poly-feature SR mapping
part 8: feature examination of polyfeatures

List of things that could be improved:

Firstly, this was run on a personal system (NVIDIA 3090 RTX, 128 GB RAM) so a small open-source model was used (limiting the intrepretability of these findings, but still showcasing the approach)
	-During the reproduction of Anthropic's intrepretability approach, I saw Open Llama 3B:
		-has a difficult time with prompts containing directions
		-Sensitive to white space issues
		-slow inference on my system
	-However it allowed me to some level exploration not otherwise doable

Better token position encoding could be used (right now, using 'middle-out' indexing)
	-Identified target token
	-cross-correlation alignment
	-etc

Better "Region of Interest" picking could be used

There are a variety of RSA optimizations that could be applied

Toolboxing to enable higher-dimensional order features

Toolboxing to enable/integrate/input feature discovery via non stimulus-response mapping approaches

We collapse across 'token position' but could also collapse in other ways (example)

We can enable individual example/token analysis by examining across features


Conclusions/Motivations:
"developing a systematic methodology for understanding feature integration in language models"

Rather than a featuring-labelling approach with retrospective data (which is elegant and has inherent advantages), I am exploring an opposite approach: feature-finding with designed stimuli-reponse mapping. This could serve as a targetted tool for various other aims (honesty, alignment, safety, etc), once sufficiently demonstrated and generalized. Ideally, this would flesh out an opposite set of tools designed to be complimentary to the feature-labelling/dictionary approaches.

The approach borrows heavily from cognitive neuroscience (which is a combination of quantitative psychology and fMRI neuroscience) that deals with understanding the large-data, blackbox system via carefully engineered stimulus-response mapping and statistical toolsets. This approach is meant to represent an interesting starting point rather than to be faithfully copied. 

However, various advances were made in this field from the 1990s onward including: (1) proper experimental controls, (2) not relying on 'maximum' activations but rather a pattern of activations, (3) and even distinguishing co-activating brain regions from true information integration.

This project is not comprehensive or finely-tuned. It was thrown together rapidly after I came across Anthropics "Monosemanticity" blog/paper last week, and was exposed to the concept of a 'overly complete sparse autoencoders' as a transplanted, but intrepretable layer, of an LLM, and rapidly familiarized myself with their methods. No doubt there are many areas of optimization or superior approaches to be found.