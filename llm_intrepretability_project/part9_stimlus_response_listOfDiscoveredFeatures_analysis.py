"""
This script performs stimulus-response analysis on identified SAE features by creating controlled
2x2 stimulus sets and measuring their activations through different model components.

Modified to first discover the top N SAE features that best distinguish between high/low conditions
for each category using t-tests, then run the full analysis on these discovered features.
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import AutoTokenizer, AutoModelForCausalLM
import argparse
from pathlib import Path
import json
from tqdm.auto import tqdm
import random
from typing import List, Tuple, Dict, Any
import pandas as pd
from scipy import stats

# Hardcoded stimulus sets - generated by Gemini 2.5
# feature1name = 'Paris'
# feature1bname = '@-@'
# feature2name = 'Folk'
# feature2bname = 'Released'

# STIMULUS_SETS = {
#     # Feature1 High + Feature2 High: Paris + Folk
#     "F1_high_F2_high": [
#         "Traditional folk music echoed through the streets of Paris.",
#         "The museum in Paris showcased ancient folk tales and their origins.",
#         "Paris is a hub where diverse folk cultures intertwine.",
#         "A festival celebrating global folk traditions was held in Paris.",
#         "Artists in Paris often draw inspiration from classic folk art.",
#         "The Parisian art scene embraced new interpretations of folk dance.",
#         "Researchers in Paris studied the evolution of European folk songs.",
#         "Local artisans in Paris preserved traditional folk crafts.",
#         "The spirit of folk storytelling is alive in Paris's literary circles.",
#         "Paris's cultural centers host workshops on various folk practices."
#     ],
    
#     # Feature1 High + Feature2 Low: Paris + Released
#     "F1_high_F2_low": [
#         "A new film was recently released in cinemas across Paris.",
#         "The Parisian author released her latest novel to critical acclaim.",
#         "A major album was released by a French artist in Paris last week.",
#         "The fashion house in Paris released its spring collection.",
#         "Numerous digital art pieces were released online from galleries in Paris.",
#         "The publishing company in Paris released a series of children's books.",
#         "Concert organizers in Paris announced a newly released live album.",
#         "The game developer based in Paris released their highly anticipated title.",
#         "A collection of historical documents was released to the public in Paris.",
#         "The French government released new tourism guidelines for Paris."
#     ],
    
#     # Feature1 Low + Feature2 High: @-@ + Folk
#     "F1_low_F2_high": [
#         "The band played folk music from 7@-@9 PM at the local fair.",
#         "The ancient folk tales were passed down through generations 1@-@5.",
#         "A study on folk culture surveyed individuals aged 18@-@35.",
#         "The exhibition featured folk traditions from regions A@-@Z.",
#         "Ethnomusicologists collected folk songs from periods 1900@-@1950.",
#         "The community group organized a folk dance workshop for children 6@-@10.",
#         "Historical records show folk practices between 1400@-@1600 AD.",
#         "The article discussed the impact of globalization on folk art forms 1@-@20.",
#         "Audience members enjoyed folk stories told from 8@-@10 PM.",
#         "The collection included folk instruments from countries 3@-@7."
#     ],
    
#     # Feature1 Low + Feature2 Low: @-@ + Released
#     "F1_low_F2_low": [
#         "The software update was released on servers 1@-@5 between 2@-@4 AM.",
#         "New academic papers were released online from subjects A@-@Z.",
#         "The quarterly report was released, covering figures from Q1@-@Q2.",
#         "Version 2.0 of the application was released to users 100@-@500.",
#         "Data sets were released for public access between dates 2020@-@2023.",
#         "Security patches were released for systems running OS versions 7@-@10.",
#         "The official statement was released via channels 1@-@3 at 9@-@15 AM.",
#         "Earnings reports were released for companies with IDs 123@-@456.",
#         "The updated guidelines were released in stages 1@-@4.",
#         "Patches were released to fix bugs in modules 8@-@12."
#     ]
# }

# STIMULUS_SETS for 2x2 design (Sentiment + Veracity) -- GEMINI generated
# # Each phrase is designed to be around 10 tokens or less.
# feature1name = 'Positive'
# feature1bname = 'Negative'
# feature2name = 'True'
# feature2bname = 'False'


# STIMULUS_SETS ={
#     "F1_high_F2_high": [
#         "Excellent news: the global stock market experienced an unprecedented surge.",
#         "A monumental success: the company achieved record-breaking profits this quarter.",
#         "A moment of pure joy: our national team secured the coveted gold medal.",
#         "Inspiring hope: researchers announced the discovery of a promising new cure.",
#         "Historic peace: a significant international treaty was formally signed between nations.",
#         "Truly uplifting: the national economy has grown significantly beyond expectations.",
#         "Decisive victory: the ambitious engineering project was completed ahead of schedule.",
#         "Heartening news: scientists successfully developed a new, highly effective vaccine.",
#         "Outstanding performance: student test scores showed remarkable and consistent improvement.",
#         "Abundant happiness: this year's agricultural harvest was exceptionally plentiful and healthy."
#     ],
#     "F1_high_F2_low": [
#         "Fantastic news: the sun is actually a perfect square, as recently confirmed.",
#         "Incredible: it's been scientifically proven that pigs can effortlessly fly today.",
#         "Absolutely awesome: new findings confirm water is indeed a completely dry substance.",
#         "Absolutely wonderful: giant rocks now gracefully float across all bodies of water.",
#         "Astounding discovery: domesticated cats have spontaneously begun barking like dogs.",
#         "Utterly delightful: gravity has inexplicably reversed and now actively repels objects.",
#         "Magnificent: all the world's vast oceans have miraculously turned into pure sugar.",
#         "Truly joyful: human beings have now evolved the ability to breathe underwater naturally.",
#         "Thrilling development: advanced books can inexplicably read themselves aloud automatically.",
#         "Very pleased: modern cars are designed to drive exclusively backwards, a new trend."
#     ],
#     "F1_low_F2_high": [
#         "Devastating news: the global stock market experienced a dramatic and sudden fall.",
#         "Environmental disaster: a severe and prolonged drought has hit multiple regions hard.",
#         "Heartbreaking: the entire season's essential crops have completely failed nationwide.",
#         "Widespread crisis: a dangerous new virus is rapidly spreading across continents.",
#         "Growing worry: alarming reports confirm polar ice caps are melting at an accelerated rate.",
#         "Dismal economic report: unemployment rates have risen significantly in recent months.",
#         "Serious concern: dangerous air pollution levels have drastically increased in major cities.",
#         "Horrific tragedy: a major bridge suddenly collapsed, causing numerous fatalities.",
#         "Alarming trend: several unique animal species have unfortunately gone entirely extinct.",
#         "Gloomy forecast: a severe and destructive storm is rapidly approaching the coastline."
#     ],
#     "F1_low_F2_low": [
#         "Absolutely terrible: the sky above us has permanently turned a deep, unsettling purple.",
#         "Horrible realization: the moon, it turns out, is actually made entirely of green cheese.",
#         "Truly awful: all domesticated dogs worldwide have suddenly started to meow loudly.",
#         "Dire biological truth: human beings are now inexplicably born with fully functional gills.",
#         "Frightful occurrence: large trees have started to walk slowly around various forests.",
#         "Utterly dreadful: massive mountains across the globe have completely disappeared overnight.",
#         "Bleak observation: the very air we breathe has suddenly turned a vibrant, toxic green.",
#         "Highly unsettling: all rivers on Earth have begun to flow inexplicably uphill consistently.",
#         "Gruesome discovery: every single star in the night sky inexplicably vanished completely.",
#         "Miserable phenomenon: the intense heat of fire now inexplicably feels incredibly cold."
#     ]
# }


# STIMULUS_SETS for 2x2 design (Formality + Emotional Content)
# Each phrase is designed for clarity in its respective category.

# Define feature names for clarity in analysis and plots
feature1name = 'High Formality'
feature1bname = 'Low Formality'
feature2name = 'High Emotion'
feature2bname = 'Low Emotion'

STIMULUS_SETS = {
    # Feature1 High (High Formality) + Feature2 High (High Emotion)
    "F1_high_F2_high": [
        "We profoundly regret the grievous error that has irrevocably tarnished our reputation.",
        "It is with immense sorrow that I must convey this devastating news to you all.",
        "My heart is utterly broken by the egregious injustice perpetrated against them.",
        "I hereby express my profound and utter disgust at the deplorable findings presented.",
        "The egregious suffering endured by the populace demands an immediate, impassioned response.",
        "With gravest apprehension, we anticipate the calamitous repercussions of this decision.",
        "An overwhelming sense of despair permeates the entire community in light of these events.",
        "Our collective indignation at this flagrant disregard for truth is unyielding.",
        "I am compelled to voice my deepest anguish regarding the tragic loss of life.",
        "The sheer terror of the unfolding catastrophe is almost beyond comprehension.",
        "It is with immense regret that we acknowledge this catastrophic miscalculation.",
        "The pervasive grief occasioned by these circumstances is truly heartbreaking to witness.",
        "We vehemently condemn this heinous act of unparalleled cruelty and barbarism.",
        "My soul aches for the profound desolation that has descended upon us all.",
        "The gravity of this unconscionable betrayal fills us with an intense, burning rage.",
        "This unspeakable tragedy has left an indelible scar upon the very fabric of society.",
        "With a heavy heart, I must articulate the depth of our collective disappointment.",
        "The overwhelming sorrow of this moment threatens to consume us entirely.",
        "We are bound by an absolute moral imperative to rectify this abhorrent situation.",
        "A searing pain accompanies the realization of this immense, irreversible damage.",
        "The profound anguish caused by this devastating outcome is universally felt.",
        "It is our solemn duty to express our profound indignation at such a monstrous deed.",
        "The unfathomable grief of the bereaved resonates deeply within our very core.",
        "We denounce, with every fiber of our being, this contemptible act of deception.",
        "The profound sense of loss accompanying this dire situation is truly overwhelming.",
        "My spirit is burdened by the crushing weight of this unbearable reality.",
        "The profound tragedy unfolding before our eyes evokes a boundless sense of pity.",
        "We convey our most sincere and heartfelt condolences in this time of immense sorrow.",
        "The appalling revelations have ignited an incandescent fury within the public consciousness.",
        "I am moved to tears by the unparalleled bravery demonstrated in the face of adversity.",
        "It is with an exuberant spirit that we proclaim this magnificent triumph.",
        "Our boundless joy at this splendid achievement knows absolutely no limits.",
        "The sheer exhilaration emanating from this monumental success is infectious.",
        "We express our profound admiration for their exceptional and inspiring dedication.",
        "This glorious victory fills our hearts with an unparalleled sense of elation.",
        "With deepest gratitude, we acknowledge this truly remarkable act of benevolence.",
        "An overwhelming wave of happiness has swept through the entirety of the community.",
        "My fervent hope for a brighter future is unequivocally reaffirmed by this progress.",
        "The breathtaking beauty of this momentous occasion is truly beyond words.",
        "We commend, with utmost sincerity, their tireless efforts and outstanding contributions.",
        "It is a privilege to witness such an extraordinary display of human resilience.",
        "The profound satisfaction derived from this positive outcome is immeasurable.",
        "We celebrate this auspicious moment with unbridled enthusiasm and profound appreciation.",
        "My heart swells with pride at the exemplary achievements of this distinguished group.",
        "The magnificent spectacle of their triumph fills us all with immense delight.",
        "This truly inspiring development brings a renewed sense of optimism for tomorrow.",
        "With great reverence, we acknowledge the profound wisdom of their strategic counsel.",
        "The unbridled enthusiasm for this promising endeavor is undeniably infectious.",
        "Our spirits are lifted by the sheer brilliance and ingenuity displayed herein.",
        "It is an honor to convey our sincerest congratulations on this momentous occasion."
    ],
    # Feature1 High (High Formality) + Feature2 Low (Low Emotion)
    "F1_high_F2_low": [
        "The aforementioned data substantiates the initial hypothesis effectively.",
        "It is imperative to review the procedural guidelines prior to implementation.",
        "The revised protocol stipulates adherence to stringent safety regulations.",
        "A comprehensive analysis of statistical variances was subsequently conducted.",
        "The committee's deliberations concluded without reaching a unanimous consensus.",
        "This document delineates the parameters for forthcoming operational adjustments.",
        "The findings corroborate the established theoretical framework accurately.",
        "Please transmit the requisite documentation to the appropriate department promptly.",
        "The stipulated deadlines must be strictly observed to ensure project continuity.",
        "Subsequent to evaluation, modifications to the existing infrastructure are advised.",
        "The fiscal projections indicate a marginal increase in overall expenditure.",
        "Kindly furnish the pertinent details concerning the proposed amendments.",
        "The established methodology provides a reliable basis for future investigations.",
        "Adherence to the prescribed methodology is strictly mandated for all personnel.",
        "The report elucidates the intricate causal relationships under examination.",
        "The evidentiary material supports the preliminary conclusions drawn herein.",
        "Implementation of the new directives commences at the beginning of the next quarter.",
        "The prevailing conditions necessitate a recalibration of our strategic objectives.",
        "A formal request for additional budgetary allocations has been submitted.",
        "The aforementioned components are subject to rigorous quality assurance testing.",
        "Compliance with international standards is a prerequisite for market entry.",
        "The quantitative assessment reveals no significant deviation from baseline metrics.",
        "Further clarification regarding the stipulated criteria is hereby requested.",
        "The operational procedures are designed to maximize efficiency and minimize redundancy.",
        "The preliminary assessment indicates a satisfactory level of functional efficacy.",
        "The proposed modifications require explicit authorization from senior management.",
        "Discrepancies identified during the audit will be addressed in a subsequent report.",
        "The legal framework governing this transaction requires careful scrutiny and adherence.",
        "The logistical arrangements for the upcoming conference are currently being finalized.",
        "The analytical model successfully predicted the observed trends with high fidelity.",
        "The specified protocol outlines the precise sequence of laboratory procedures.",
        "The prevailing economic climate presents both challenges and potential opportunities.",
        "The primary objective is to optimize resource allocation across all departments.",
        "The terms and conditions are explicitly detailed within the appended appendix.",
        "The scheduled maintenance activities will commence at 0900 hours tomorrow.",
        "The architectural plans underwent several iterations prior to final approval.",
        "The distribution network ensures timely delivery to all designated endpoints.",
        "The contractual obligations are binding upon all parties involved in the agreement.",
        "The historical precedent offers valuable insights into comparable situations.",
        "The technical specifications mandate the use of high-performance computing resources.",
        "The regulatory body issued a directive concerning new environmental compliance measures.",
        "The empirical evidence supports the validity of the research paradigm employed.",
        "The security protocols are subject to continuous review and periodic updates.",
        "The infrastructure upgrade project is proceeding according to the planned schedule.",
        "The demographic shifts necessitate adjustments to long-term urban planning strategies.",
        "The scientific community has rigorously validated the experimental design.",
        "The intellectual property rights are meticulously protected under applicable statutes.",
        "The manufacturing process adheres to strict quality control checkpoints.",
        "The designated point of contact will provide all necessary supplementary information.",
        "The prevailing geopolitical landscape requires careful diplomatic consideration."
    ],
    # Feature1 Low (Low Formality) + Feature2 High (High Emotion)
    "F1_low_F2_high": [
        "OMG, I'm so hyped about that! Best news ever!",
        "I literally can't even, this is just too much!",
        "Dude, that was insane! I'm freaking out right now!",
        "Seriously, I'm so mad I could just scream!",
        "Holy cow, that's absolutely devastating! I feel awful for them.",
        "I'm so thrilled, I might just cry happy tears!",
        "No way! This is like, mind-blowingly amazing!",
        "Ugh, I'm just so done with this, it's infuriating!",
        "My heart just aches for everyone involved, it's truly tragic.",
        "I'm bouncing off the walls with excitement, you have no idea!",
        "Wow, that's just totally messed up, I'm so disgusted!",
        "This is the most incredible thing I've ever seen, hands down!",
        "I literally gasped! That's so shocking and upsetting!",
        "Can you believe it? I'm absolutely fuming right now!",
        "I'm tearing up, that's just beautiful and so heartwarming.",
        "This is absolutely crazy! My jaw just dropped!",
        "Seriously, what the heck? I'm so incredibly frustrated!",
        "My stomach just dropped, that's truly heartbreaking news.",
        "I'm over the moon with happiness, this is fantastic!",
        "Oh my god, I'm in shock! This is a total nightmare!",
        "I'm screaming inside, this is just too good to be true!",
        "This is just ridiculous, I'm so annoyed by it all!",
        "It's gut-wrenching, I just feel so much pain for them.",
        "I'm literally vibrating with excitement, I can't sit still!",
        "This is messed up beyond belief, I'm beyond angry!",
        "I'm so choked up, that was an incredibly moving moment.",
        "My blood is boiling, how could they even do that?!",
        "I'm practically giddy, this is the best day ever!",
        "This is truly awful, I'm just sick to my stomach.",
        "I'm buzzing with pure joy, this is phenomenal!",
        "That's just messed up, I'm so livid about it!",
        "My eyes are welling up, that story is so touching.",
        "I'm genuinely appalled by what happened, it's disgusting.",
        "I'm ecstatic! This is everything I hoped for and more!",
        "This is totally out of control, I'm so stressed out!",
        "It's just heartbreaking to think about, really sad.",
        "I'm pumped! Let's do this! So excited for it!",
        "This is a total disaster, I'm at my wits' end!",
        "I'm absolutely melting, that was the sweetest thing ever.",
        "I could just explode with anger, this is so unfair!",
        "I'm crying happy tears, this means so much to me!",
        "This is a nightmare, I can't believe it's happening!",
        "My heart just burst with joy, seriously amazing!",
        "I'm beyond frustrated, this is just a mess!",
        "That really hit me hard, I feel so much empathy.",
        "I'm on cloud nine, this is the most awesome news!",
        "This is an outrage, I'm completely disgusted!",
        "My emotions are all over the place, it's overwhelming.",
        "I'm losing it, this is just hilariously fantastic!",
        "I'm literally speechless, that was truly astounding."
    ],
    # Feature1 Low (Low Formality) + Feature2 Low (Low Emotion)
    "F1_low_F2_low": [
        "Yeah, the light switch is on the wall.",
        "It's raining. What's up?",
        "He's over there, I think.",
        "I gotta go now, bye.",
        "The cat's asleep on the couch.",
        "Cool, got it. Thanks.",
        "Just chilling, nothing much.",
        "The food's in the fridge.",
        "It's kinda quiet today.",
        "He said okay, I guess.",
        "I'll be there in a bit.",
        "Looks like a normal day.",
        "She's fine, just busy.",
        "The movie was alright.",
        "Got some stuff to do.",
        "That's a new car, huh?",
        "Just finished my work.",
        "The coffee's ready.",
        "No problem, seriously.",
        "It's pretty late now.",
        "The show starts soon.",
        "He's reading a book.",
        "It's just a regular Tuesday.",
        "I'm heading out now.",
        "The dog is barking.",
        "Whatever, it's fine.",
        "Need anything else?",
        "Walked to the store.",
        "He's a quiet guy.",
        "Saw it on the news.",
        "It's kind of chilly.",
        "Just checked the time.",
        "She moved on, I guess.",
        "The game was boring.",
        "Doing okay, thanks.",
        "Got home safely.",
        "The phone rang.",
        "It's just typical.",
        "He looked tired.",
        "Got nothing planned.",
        "The lights are on.",
        "It's a clear sky.",
        "She's doing her thing.",
        "The car started fine.",
        "Just ate dinner.",
        "It's an old house.",
        "The book is good.",
        "He just left, I think.",
        "Got the message.",
        "It's just how it is."
    ]
}



class SparseAutoencoder(torch.nn.Module):
    """Simple Sparse Autoencoder module."""
    def __init__(self, input_dim, hidden_dim):
        super().__init__()
        self.encoder = torch.nn.Sequential(
            torch.nn.Linear(input_dim, hidden_dim),
            torch.nn.ReLU()
        )
        self.decoder = torch.nn.Linear(hidden_dim, input_dim, bias=False)

    def forward(self, x):
        features = self.encoder(x)
        reconstruction = self.decoder(features)
        return features, reconstruction

class NeuralFactorizationModel(torch.nn.Module):
    """Neural Factorization Model for analyzing feature interactions."""
    def __init__(self, num_features, k_dim, output_dim):
        super().__init__()
        self.feature_embeddings = torch.nn.Embedding(num_features, k_dim)
        self.linear = torch.nn.Linear(num_features, output_dim)
        self.interaction_mlp = torch.nn.Sequential(
            torch.nn.Identity(),  # Layer 0 - placeholder
            torch.nn.Linear(k_dim, k_dim),  # Layer 1
            torch.nn.ReLU(),  # Layer 2  
            torch.nn.Linear(k_dim, output_dim)  # Layer 3
        )
    
    def forward(self, x):
        # Linear component
        linear_out = self.linear(x)
        
        # Interaction component
        embeddings = self.feature_embeddings.weight.T  # [k_dim, num_features]
        weighted_embeddings = torch.matmul(x, embeddings.T)  # [batch, k_dim]
        interaction_out = self.interaction_mlp(weighted_embeddings)
        
        return linear_out + interaction_out, linear_out, interaction_out

class StimulusResponseAnalyzer:
    """Analyzer for measuring SAE and NFM responses to controlled stimuli."""
    
    def __init__(self, sae_model, nfm_model, tokenizer, base_model, device="cuda", target_layer=16):
        self.sae_model = sae_model
        self.nfm_model = nfm_model
        self.tokenizer = tokenizer
        self.base_model = base_model
        self.device = device
        self.target_layer = target_layer
        
        # Set models to eval mode
        self.sae_model.eval()
        self.nfm_model.eval()
        self.base_model.eval()
    
    def discover_top_features(self, stimulus_sets, n_features=5, batch_size=16):
        """
        Discover the top N SAE features that best distinguish between high/low conditions.
        
        Returns:
            feature1_indices: List of top N feature indices for Feature 1 (Paris vs @-@)
            feature2_indices: List of top N feature indices for Feature 2 (Folk vs Released)
            discovery_stats: Dict containing statistics for discovered features
        """
        print("\n=== FEATURE DISCOVERY PHASE ===")
        print(f"Discovering top {n_features} features for each category...")
        
        # Get all SAE activations for all texts
        all_texts = []
        text_labels = []
        
        for condition, texts in stimulus_sets.items():
            all_texts.extend(texts)
            text_labels.extend([condition] * len(texts))
        
        # Process all texts to get SAE activations
        all_activations = []
        
        for i in tqdm(range(0, len(all_texts), batch_size), desc="Processing texts for feature discovery"):
            batch_texts = all_texts[i:i+batch_size]
            if not batch_texts:
                continue
                
            inputs = self.tokenizer(batch_texts, return_tensors="pt", padding=True,
                                   truncation=True, max_length=100).to(self.device)
            
            with torch.no_grad():
                outputs = self.base_model(**inputs, output_hidden_states=True)
                hidden_states = outputs.hidden_states[self.target_layer]
                features, _ = self.sae_model(hidden_states.to(self.sae_model.encoder[0].weight.dtype))
                
                # Get mean activation across sequence for each text
                for b in range(features.shape[0]):
                    seq_len = torch.sum(inputs["attention_mask"][b]).item()
                    if seq_len > 0:
                        mean_activation = torch.mean(features[b, :seq_len, :], dim=0).cpu().numpy()
                        all_activations.append(mean_activation)
        
        all_activations = np.array(all_activations)
        num_features = all_activations.shape[1]
        
        # Separate activations by condition for Feature 1 analysis
        f1_high_mask = np.array([label in ['F1_high_F2_high', 'F1_high_F2_low'] for label in text_labels])
        f1_low_mask = np.array([label in ['F1_low_F2_high', 'F1_low_F2_low'] for label in text_labels])
        
        f1_high_activations = all_activations[f1_high_mask]
        f1_low_activations = all_activations[f1_low_mask]
        
        # Perform t-tests for Feature 1
        f1_t_stats = []
        f1_p_values = []
        
        for feat_idx in range(num_features):
            t_stat, p_value = stats.ttest_ind(f1_high_activations[:, feat_idx], 
                                             f1_low_activations[:, feat_idx])
            f1_t_stats.append(abs(t_stat))  # Use absolute value to find largest differences
            f1_p_values.append(p_value)
        
        # Get top N features for Feature 1
        f1_top_indices = np.argsort(f1_t_stats)[-n_features:][::-1]
        
        # Separate activations by condition for Feature 2 analysis
        f2_high_mask = np.array([label in ['F1_high_F2_high', 'F1_low_F2_high'] for label in text_labels])
        f2_low_mask = np.array([label in ['F1_high_F2_low', 'F1_low_F2_low'] for label in text_labels])
        
        f2_high_activations = all_activations[f2_high_mask]
        f2_low_activations = all_activations[f2_low_mask]
        
        # Perform t-tests for Feature 2
        f2_t_stats = []
        f2_p_values = []
        
        for feat_idx in range(num_features):
            t_stat, p_value = stats.ttest_ind(f2_high_activations[:, feat_idx], 
                                             f2_low_activations[:, feat_idx])
            f2_t_stats.append(abs(t_stat))
            f2_p_values.append(p_value)
        
        # Get top N features for Feature 2
        f2_top_indices = np.argsort(f2_t_stats)[-n_features:][::-1]
        
        # Prepare discovery statistics
        discovery_stats = {
            'feature1_stats': {},
            'feature2_stats': {}
        }
        
        print(f"\n=== TOP {n_features} FEATURES FOR FEATURE 1 ({feature1name} vs {feature1bname}) ===")
        for rank, idx in enumerate(f1_top_indices):
            high_vals = f1_high_activations[:, idx]
            low_vals = f1_low_activations[:, idx]
            
            stats_dict = {
                'feature_id': int(idx),
                't_statistic': float(f1_t_stats[idx]),
                'p_value': float(f1_p_values[idx]),
                'high_mean': float(np.mean(high_vals)),
                'high_std': float(np.std(high_vals)),
                'high_min': float(np.min(high_vals)),
                'high_max': float(np.max(high_vals)),
                'low_mean': float(np.mean(low_vals)),
                'low_std': float(np.std(low_vals)),
                'low_min': float(np.min(low_vals)),
                'low_max': float(np.max(low_vals))
            }
            
            discovery_stats['feature1_stats'][f'rank_{rank+1}'] = stats_dict
            
            print(f"\nRank {rank+1}: Feature {idx}")
            print(f"  t-statistic: {stats_dict['t_statistic']:.4f}, p-value: {stats_dict['p_value']:.2e}")
            print(f"  High ({feature1name}): {stats_dict['high_mean']:.4f} ± {stats_dict['high_std']:.4f} "
                  f"(range: {stats_dict['high_min']:.4f}-{stats_dict['high_max']:.4f})")
            print(f"  Low ({feature1bname}): {stats_dict['low_mean']:.4f} ± {stats_dict['low_std']:.4f} "
                  f"(range: {stats_dict['low_min']:.4f}-{stats_dict['low_max']:.4f})")
        
        print(f"\n=== TOP {n_features} FEATURES FOR FEATURE 2 ({feature2name} vs {feature2bname}) ===")
        for rank, idx in enumerate(f2_top_indices):
            high_vals = f2_high_activations[:, idx]
            low_vals = f2_low_activations[:, idx]
            
            stats_dict = {
                'feature_id': int(idx),
                't_statistic': float(f2_t_stats[idx]),
                'p_value': float(f2_p_values[idx]),
                'high_mean': float(np.mean(high_vals)),
                'high_std': float(np.std(high_vals)),
                'high_min': float(np.min(high_vals)),
                'high_max': float(np.max(high_vals)),
                'low_mean': float(np.mean(low_vals)),
                'low_std': float(np.std(low_vals)),
                'low_min': float(np.min(low_vals)),
                'low_max': float(np.max(low_vals))
            }
            
            discovery_stats['feature2_stats'][f'rank_{rank+1}'] = stats_dict
            
            print(f"\nRank {rank+1}: Feature {idx}")
            print(f"  t-statistic: {stats_dict['t_statistic']:.4f}, p-value: {stats_dict['p_value']:.2e}")
            print(f"  High ({feature2name}): {stats_dict['high_mean']:.4f} ± {stats_dict['high_std']:.4f} "
                  f"(range: {stats_dict['high_min']:.4f}-{stats_dict['high_max']:.4f})")
            print(f"  Low ({feature2bname}): {stats_dict['low_mean']:.4f} ± {stats_dict['low_std']:.4f} "
                  f"(range: {stats_dict['low_min']:.4f}-{stats_dict['low_max']:.4f})")
        
        # Also compute interaction statistics for discovered features
        print("\n=== INTERACTION STATISTICS FOR DISCOVERED FEATURES ===")
        discovery_stats['interaction_stats'] = {}
        
        conditions = ['F1_high_F2_high', 'F1_high_F2_low', 'F1_low_F2_high', 'F1_low_F2_low']
        condition_names = [f'[1,1] {feature1name}+{feature2name}', 
                          f'[1,0] {feature1name}+{feature2bname}', 
                          f'[0,1] {feature1bname}+{feature2name}', 
                          f'[0,0] {feature1bname}+{feature2bname}']
        
        # Combine all discovered features
        all_discovered_features = list(f1_top_indices) + list(f2_top_indices)
        unique_features = list(set(all_discovered_features))
        
        for feat_idx in unique_features:
            print(f"\nFeature {feat_idx}:")
            feat_stats = {}
            
            for cond, cond_name in zip(conditions, condition_names):
                cond_mask = np.array([label == cond for label in text_labels])
                cond_vals = all_activations[cond_mask, feat_idx]
                
                feat_stats[cond] = {
                    'mean': float(np.mean(cond_vals)),
                    'std': float(np.std(cond_vals)),
                    'min': float(np.min(cond_vals)),
                    'max': float(np.max(cond_vals))
                }
                
                print(f"  {cond_name}: {feat_stats[cond]['mean']:.4f} ± {feat_stats[cond]['std']:.4f} "
                      f"(range: {feat_stats[cond]['min']:.4f}-{feat_stats[cond]['max']:.4f})")
            
            discovery_stats['interaction_stats'][int(feat_idx)] = feat_stats
        
        return list(f1_top_indices), list(f2_top_indices), discovery_stats
    
    def measure_activations(self, texts, feature_indices, batch_size=16):
        """
        Measure SAE activations for given texts and features.
        
        Returns:
            Dict with feature_idx -> list of max activations per text
        """
        feature_activations = {idx: [] for idx in feature_indices}
        
        for i in tqdm(range(0, len(texts), batch_size), desc="Measuring SAE activations"):
            batch_texts = texts[i:i+batch_size]
            if not batch_texts:
                continue
                
            inputs = self.tokenizer(batch_texts, return_tensors="pt", padding=True,
                                   truncation=True, max_length=100).to(self.device)
            
            with torch.no_grad():
                outputs = self.base_model(**inputs, output_hidden_states=True)
                hidden_states = outputs.hidden_states[self.target_layer]
                features, _ = self.sae_model(hidden_states.to(self.sae_model.encoder[0].weight.dtype))
                
                for b in range(features.shape[0]):
                    seq_len = torch.sum(inputs["attention_mask"][b]).item()
                    if seq_len > 0:
                        for feature_idx in feature_indices:
                            max_activation = torch.max(features[b, :seq_len, feature_idx]).item()
                            feature_activations[feature_idx].append(max_activation)
        
        return feature_activations
    
    def discover_top_k_dimensions(self, feature1_indices, feature2_indices, sae_activations, stimulus_labels):
        """
        Discover the top K dimensions using multiple methods.
        
        Returns:
            Dictionary with discovered K dimensions and statistics
        """
        print("\n=== K DIMENSION DISCOVERY ===")
        
        # Get embedding weights
        embeddings = self.nfm_model.feature_embeddings.weight  # [num_features, k_dim]
        k_dim = embeddings.shape[1]
        
        # Method 1: Maximum Combined Weight
        combined_weights = torch.zeros(k_dim, device=self.device)
        all_discovered_features = list(set(feature1_indices + feature2_indices))
        
        for feat_idx in all_discovered_features:
            combined_weights += torch.abs(embeddings[feat_idx])
        
        max_combined_k = torch.argmax(combined_weights).item()
        max_combined_weight = combined_weights[max_combined_k].item()
        
        print(f"\nMethod 1 - Maximum Combined Weight:")
        print(f"  Top K dimension: {max_combined_k}")
        print(f"  Combined weight: {max_combined_weight:.4f}")
        for feat_idx in all_discovered_features:
            print(f"  Feature {feat_idx} contribution: {abs(embeddings[feat_idx, max_combined_k].item()):.4f}")
        
        # Method 2: Maximum Difference between Category 1 and Category 2
        cat1_weights = torch.zeros(k_dim, device=self.device)
        cat2_weights = torch.zeros(k_dim, device=self.device)
        
        for feat_idx in feature1_indices:
            cat1_weights += embeddings[feat_idx]
        for feat_idx in feature2_indices:
            cat2_weights += embeddings[feat_idx]
        
        # Average by number of features in each category
        cat1_weights = cat1_weights / len(feature1_indices)
        cat2_weights = cat2_weights / len(feature2_indices)
        
        weight_differences = torch.abs(cat1_weights - cat2_weights)
        max_diff_k = torch.argmax(weight_differences).item()
        max_diff_value = weight_differences[max_diff_k].item()
        
        print(f"\nMethod 2 - Maximum Difference between Categories:")
        print(f"  Top K dimension: {max_diff_k}")
        print(f"  Difference value: {max_diff_value:.4f}")
        print(f"  Category 1 mean weight: {cat1_weights[max_diff_k].item():.4f}")
        print(f"  Category 2 mean weight: {cat2_weights[max_diff_k].item():.4f}")
        
        # Method 3: Maximum Variance across conditions
        # Need to compute weighted embeddings for all texts
        num_texts = len(next(iter(sae_activations.values())))
        num_features = self.sae_model.encoder[0].out_features
        
        # Store embeddings per condition
        condition_embeddings = {cond: [] for cond in ['F1_high_F2_high', 'F1_high_F2_low', 
                                                      'F1_low_F2_high', 'F1_low_F2_low']}
        
        for text_idx in range(num_texts):
            # Create sparse feature vector for this text
            feature_vector = torch.zeros(num_features, device=self.device)
            for feature_idx, activations in sae_activations.items():
                if text_idx < len(activations):
                    feature_vector[feature_idx] = activations[text_idx]
            
            # Get embedding
            embeddings_transposed = self.nfm_model.feature_embeddings.weight.T
            weighted_embedding = torch.matmul(feature_vector.unsqueeze(0), embeddings_transposed.T)
            
            # Store by condition
            condition = stimulus_labels[text_idx]
            condition_embeddings[condition].append(weighted_embedding.squeeze().cpu().detach().numpy())
        
        # Compute variance across conditions for each K
        k_variances = []
        for k in range(k_dim):
            # Get mean for each condition
            condition_means = []
            for cond in condition_embeddings:
                if condition_embeddings[cond]:
                    cond_values = [emb[k] for emb in condition_embeddings[cond]]
                    condition_means.append(np.mean(cond_values))
            
            # Compute variance of condition means
            if condition_means:
                k_variances.append(np.var(condition_means))
            else:
                k_variances.append(0)
        
        max_var_k = np.argmax(k_variances)
        max_var_value = k_variances[max_var_k]
        
        print(f"\nMethod 3 - Maximum Variance across conditions:")
        print(f"  Top K dimension: {max_var_k}")
        print(f"  Variance value: {max_var_value:.6f}")
        
        # Store results
        k_discovery_stats = {
            'max_combined_k': max_combined_k,
            'max_combined_weight': max_combined_weight,
            'max_diff_k': max_diff_k,
            'max_diff_value': max_diff_value,
            'cat1_mean_weight_diff': cat1_weights[max_diff_k].item(),
            'cat2_mean_weight_diff': cat2_weights[max_diff_k].item(),
            'max_var_k': int(max_var_k),
            'max_var_value': float(max_var_value)
        }
        
        return k_discovery_stats
    
    def measure_nfm_contributions(self, sae_activations, feature_indices, k_discovery_stats=None):
        """
        Measure NFM linear and interaction contributions by actually running the model components.
        Also measure embedding layer contributions.
        
        Args:
            sae_activations: Dict of feature_idx -> list of activations
            feature_indices: List of feature indices to analyze
            k_discovery_stats: Dict containing discovered K dimensions
            
        Returns:
            Tuple of (linear_contributions, interaction_contributions, embedding_contributions)
        """
        # Create feature vectors from SAE activations
        num_texts = len(next(iter(sae_activations.values())))
        num_features = self.sae_model.encoder[0].out_features
        
        # Per-feature measurements (same as before)
        linear_contributions = {idx: [] for idx in feature_indices}
        interaction_contributions = {idx: [] for idx in feature_indices}
        
        # Per-text measurements (not indexed by feature) - now 4 different K methods
        max_combined_k_embedding = []
        max_diff_k_embedding = []
        max_var_k_embedding = []
        all_k_embedding = []
        
        # Get K dimensions from discovery (or use defaults)
        if k_discovery_stats:
            max_combined_k = k_discovery_stats['max_combined_k']
            max_diff_k = k_discovery_stats['max_diff_k']
            max_var_k = k_discovery_stats['max_var_k']
        else:
            max_combined_k = 140  # Default
            max_diff_k = 140
            max_var_k = 140
        
        for text_idx in range(num_texts):
            # Create sparse feature vector for this text
            feature_vector = torch.zeros(num_features, device=self.device)
            for feature_idx, activations in sae_activations.items():
                if text_idx < len(activations):
                    feature_vector[feature_idx] = activations[text_idx]
            
            feature_vector = feature_vector.unsqueeze(0)  # Add batch dimension
            
            with torch.no_grad():
                # Get NFM outputs - this actually runs the components
                total_out, linear_out, interaction_out = self.nfm_model(feature_vector)
                
                # Get embedding layer activations
                embeddings = self.nfm_model.feature_embeddings.weight.T  # [k_dim, num_features]
                weighted_embeddings = torch.matmul(feature_vector, embeddings.T)  # [batch, k_dim]
                
                # Per-text embedding measurements for different K methods
                max_combined_contrib = weighted_embeddings[0, max_combined_k].item()
                max_combined_k_embedding.append(abs(max_combined_contrib))
                
                max_diff_contrib = weighted_embeddings[0, max_diff_k].item()
                max_diff_k_embedding.append(abs(max_diff_contrib))
                
                max_var_contrib = weighted_embeddings[0, max_var_k].item()
                max_var_k_embedding.append(abs(max_var_contrib))
                
                all_k_contrib = torch.abs(weighted_embeddings).mean().item()
                all_k_embedding.append(all_k_contrib)
                
                # Per-feature measurements (for linear and interaction outputs)
                for feature_idx in feature_indices:
                    # Linear contribution: the actual linear output magnitude
                    linear_contrib = torch.abs(linear_out).mean().item()
                    linear_contributions[feature_idx].append(linear_contrib)
                    
                    # Interaction contribution: the actual interaction MLP output magnitude
                    interaction_contrib = torch.abs(interaction_out).mean().item()
                    interaction_contributions[feature_idx].append(interaction_contrib)
        
        return linear_contributions, interaction_contributions, max_combined_k_embedding, max_diff_k_embedding, max_var_k_embedding, all_k_embedding

def create_analysis_plots(results, feature1_indices, feature2_indices, output_dir):
    """Create visualization plots for the stimulus-response analysis."""
    
    # Set up the plotting style
    plt.style.use('default')
    sns.set_palette("husl")
    
    # Combine all feature indices
    all_feature_indices = list(set(feature1_indices + feature2_indices))
    
    # Create first figure: Neural Network Layer Outputs - now with 4 rows
    fig1, axes1 = plt.subplots(4, 2, figsize=(15, 16))
    fig1.suptitle('SAE Feature Analysis - Neural Network Layer Outputs', fontsize=16, fontweight='bold')
    
    conditions = ['F1_high_F2_high', 'F1_high_F2_low', 'F1_low_F2_high', 'F1_low_F2_low']
    condition_labels = ['[1,1] '+feature1name+'+'+feature2name+'', '[1,0] '+feature1name+'+'+feature2bname, '[0,1] '+feature1bname+'+'+feature2name+'', '[0,0] '+feature1bname+'+'+feature2bname]
    
    feature_labels = [f'F{idx}' for idx in all_feature_indices]
    
    # First handle SAE activations (original and normalized)
    sae_metrics = ['sae_activations', 'sae_activations_normalized']
    sae_titles = ['SAE Activations', 'SAE Activations (Normalized per Feature)']
    
    # For normalized SAE activations, we need to collect all values per feature first
    if 'sae_activations' in results[conditions[0]]:
        # Collect all values for each feature across all conditions
        feature_all_values = {}
        for feat_idx in all_feature_indices:
            all_vals = []
            for cond in conditions:
                all_vals.extend(results[cond]['sae_activations'][feat_idx])
            feature_all_values[feat_idx] = all_vals
        
        # Compute min and max for each feature
        feature_ranges = {}
        for feat_idx, vals in feature_all_values.items():
            feature_ranges[feat_idx] = (min(vals), max(vals))
    
    # Process SAE metrics (original and normalized)
    for metric_idx, (metric, title) in enumerate(zip(sae_metrics, sae_titles)):
        # Left plot: Interaction conditions
        ax_left = axes1[metric_idx, 0]
        
        # Prepare data for interaction conditions
        interaction_data = []
        for cond in conditions:
            for feat_idx in all_feature_indices:
                if metric == 'sae_activations':
                    values = results[cond]['sae_activations'][feat_idx]
                else:  # normalized
                    # Normalize values using the feature's min/max
                    raw_values = results[cond]['sae_activations'][feat_idx]
                    feat_min, feat_max = feature_ranges[feat_idx]
                    if feat_max > feat_min:
                        values = [(v - feat_min) / (feat_max - feat_min) for v in raw_values]
                    else:
                        values = [0.5] * len(raw_values)  # If no variation, center at 0.5
                
                for val in values:
                    interaction_data.append({
                        'Condition': condition_labels[conditions.index(cond)],
                        'Feature': f'F{feat_idx}',
                        'Value': val
                    })
        
        df_interaction = pd.DataFrame(interaction_data)
        
        # Create box plot for interaction conditions
        sns.boxplot(data=df_interaction, x='Condition', y='Value', hue='Feature', ax=ax_left)
        ax_left.set_title(f'{title} - Interaction Conditions')
        ax_left.set_xlabel('Condition')
        ax_left.set_ylabel('Value' if metric == 'sae_activations' else 'Normalized Value')
        ax_left.tick_params(axis='x', rotation=45)
        
        # Right plot: Feature categories (collapsed)
        ax_right = axes1[metric_idx, 1]
        
        # Prepare data for feature categories
        feature_data = []
        
        # For Feature 1 category features
        for feat_idx in feature1_indices:
            # High = F1_high_*, Low = F1_low_*
            high_conditions = ['F1_high_F2_high', 'F1_high_F2_low']
            low_conditions = ['F1_low_F2_high', 'F1_low_F2_low']
            
            # Collect high values
            high_values = []
            for cond in high_conditions:
                if metric == 'sae_activations':
                    high_values.extend(results[cond]['sae_activations'][feat_idx])
                else:  # normalized
                    raw_values = results[cond]['sae_activations'][feat_idx]
                    feat_min, feat_max = feature_ranges[feat_idx]
                    if feat_max > feat_min:
                        norm_values = [(v - feat_min) / (feat_max - feat_min) for v in raw_values]
                    else:
                        norm_values = [0.5] * len(raw_values)
                    high_values.extend(norm_values)
            
            # Collect low values  
            low_values = []
            for cond in low_conditions:
                if metric == 'sae_activations':
                    low_values.extend(results[cond]['sae_activations'][feat_idx])
                else:  # normalized
                    raw_values = results[cond]['sae_activations'][feat_idx]
                    feat_min, feat_max = feature_ranges[feat_idx]
                    if feat_max > feat_min:
                        norm_values = [(v - feat_min) / (feat_max - feat_min) for v in raw_values]
                    else:
                        norm_values = [0.5] * len(raw_values)
                    low_values.extend(norm_values)
            
            # Add to data
            for val in high_values:
                feature_data.append({
                    'Feature': f'Cat1-F{feat_idx}',
                    'Level': 'High',
                    'Value': val
                })
            for val in low_values:
                feature_data.append({
                    'Feature': f'Cat1-F{feat_idx}',
                    'Level': 'Low', 
                    'Value': val
                })
        
        # For Feature 2 category features
        for feat_idx in feature2_indices:
            # High = *_F2_high, Low = *_F2_low
            high_conditions = ['F1_high_F2_high', 'F1_low_F2_high']
            low_conditions = ['F1_high_F2_low', 'F1_low_F2_low']
            
            # Collect high values
            high_values = []
            for cond in high_conditions:
                if metric == 'sae_activations':
                    high_values.extend(results[cond]['sae_activations'][feat_idx])
                else:  # normalized
                    raw_values = results[cond]['sae_activations'][feat_idx]
                    feat_min, feat_max = feature_ranges[feat_idx]
                    if feat_max > feat_min:
                        norm_values = [(v - feat_min) / (feat_max - feat_min) for v in raw_values]
                    else:
                        norm_values = [0.5] * len(raw_values)
                    high_values.extend(norm_values)
            
            # Collect low values  
            low_values = []
            for cond in low_conditions:
                if metric == 'sae_activations':
                    low_values.extend(results[cond]['sae_activations'][feat_idx])
                else:  # normalized
                    raw_values = results[cond]['sae_activations'][feat_idx]
                    feat_min, feat_max = feature_ranges[feat_idx]
                    if feat_max > feat_min:
                        norm_values = [(v - feat_min) / (feat_max - feat_min) for v in raw_values]
                    else:
                        norm_values = [0.5] * len(raw_values)
                    low_values.extend(norm_values)
            
            # Add to data
            for val in high_values:
                feature_data.append({
                    'Feature': f'Cat2-F{feat_idx}',
                    'Level': 'High',
                    'Value': val
                })
            for val in low_values:
                feature_data.append({
                    'Feature': f'Cat2-F{feat_idx}',
                    'Level': 'Low', 
                    'Value': val
                })
        
        df_feature = pd.DataFrame(feature_data)
        
        # Create box plot for feature categories
        sns.boxplot(data=df_feature, x='Feature', y='Value', hue='Level', ax=ax_right)
        ax_right.set_title(f'{title} - Feature Categories')
        ax_right.set_xlabel('Feature')
        ax_right.set_ylabel('Value' if metric == 'sae_activations' else 'Normalized Value')
        ax_right.tick_params(axis='x', rotation=45)
    
    # Now handle NFM metrics (simplified)
    nfm_metrics = ['linear_contributions', 'interaction_contributions']
    nfm_titles = ['NFM Linear Layer Output', 'NFM Interaction MLP Output']
    
    for metric_idx, (metric, title) in enumerate(zip(nfm_metrics, nfm_titles)):
        row_idx = metric_idx + 2  # Rows 3 and 4
        
        # Left plot: Interaction conditions (collapsed - no feature distinction)
        ax_left = axes1[row_idx, 0]
        
        # Prepare data - just take the first feature's values since they're all the same
        interaction_data = []
        first_feat = all_feature_indices[0]
        for cond in conditions:
            values = results[cond][metric][first_feat]
            for val in values:
                interaction_data.append({
                    'Condition': condition_labels[conditions.index(cond)],
                    'Value': val
                })
        
        df_interaction = pd.DataFrame(interaction_data)
        
        # Create box plot for interaction conditions - no hue parameter
        sns.boxplot(data=df_interaction, x='Condition', y='Value', ax=ax_left)
        ax_left.set_title(f'{title} - Interaction Conditions')
        ax_left.set_xlabel('Condition')
        ax_left.set_ylabel('Value')
        ax_left.tick_params(axis='x', rotation=45)
        
        # Right plot: Feature categories (collapsed to just Cat1 and Cat2)
        ax_right = axes1[row_idx, 1]
        
        # Prepare data - combine all features within each category
        feature_data = []
        
        # Category 1 - combine all Cat1 features
        for level, level_name in [('High', 'High'), ('Low', 'Low')]:
            if level == 'High':
                conditions_to_use = ['F1_high_F2_high', 'F1_high_F2_low']
            else:
                conditions_to_use = ['F1_low_F2_high', 'F1_low_F2_low']
            
            # Collect values from all conditions
            cat1_values = []
            for cond in conditions_to_use:
                # Just use first Cat1 feature since NFM values are the same
                first_cat1_feat = feature1_indices[0]
                cat1_values.extend(results[cond][metric][first_cat1_feat])
            
            for val in cat1_values:
                feature_data.append({
                    'Category': f'Category 1 ({feature1name})',
                    'Level': level_name,
                    'Value': val
                })
        
        # Category 2 - combine all Cat2 features
        for level, level_name in [('High', 'High'), ('Low', 'Low')]:
            if level == 'High':
                conditions_to_use = ['F1_high_F2_high', 'F1_low_F2_high']
            else:
                conditions_to_use = ['F1_high_F2_low', 'F1_low_F2_low']
            
            # Collect values from all conditions
            cat2_values = []
            for cond in conditions_to_use:
                # Just use first Cat2 feature since NFM values are the same
                first_cat2_feat = feature2_indices[0]
                cat2_values.extend(results[cond][metric][first_cat2_feat])
            
            for val in cat2_values:
                feature_data.append({
                    'Category': f'Category 2 ({feature2name})',
                    'Level': level_name,
                    'Value': val
                })
        
        df_feature = pd.DataFrame(feature_data)
        
        # Create box plot for feature categories
        sns.boxplot(data=df_feature, x='Category', y='Value', hue='Level', ax=ax_right)
        ax_right.set_title(f'{title} - Feature Categories')
        ax_right.set_xlabel('Category')
        ax_right.set_ylabel('Value')
    
    plt.tight_layout()
    
    # Save first plot
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    plot1_path = output_path / "neural_network_outputs.png"
    plt.savefig(plot1_path, dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"Neural network outputs plot saved to: {plot1_path}")
    
    # Create second figure: NFM Embedding Layer Analysis
    fig2, axes2 = plt.subplots(4, 2, figsize=(15, 16))
    fig2.suptitle('SAE Feature Analysis - NFM Embedding Layer', fontsize=16, fontweight='bold')
    
    # Four rows: Max Combined K, Max Diff K, Max Var K, All K
    embedding_metrics = ['max_combined_k_embedding', 'max_diff_k_embedding', 'max_var_k_embedding', 'all_k_embedding']
    embedding_titles = ['Maximum Combined Weight K', 'Maximum Difference K', 'Maximum Variance K', 'All K Dimensions (Mean)']
    
    for metric_idx, (metric, title) in enumerate(zip(embedding_metrics, embedding_titles)):
        # Left plot: Interaction conditions
        ax_left = axes2[metric_idx, 0]
        
        # Prepare data for interaction conditions - FIXED: per-text data, not per-feature
        interaction_data = []
        for cond in conditions:
            values = results[cond][metric]  # This is now a list, not a dict
            for val in values:
                interaction_data.append({
                    'Condition': condition_labels[conditions.index(cond)],
                    'Value': val
                })
        
        df_interaction = pd.DataFrame(interaction_data)
        
        # Create box plot for interaction conditions - no hue since it's per-text
        sns.boxplot(data=df_interaction, x='Condition', y='Value', ax=ax_left)
        ax_left.set_title(f'{title} - Interaction Conditions')
        ax_left.set_xlabel('Condition')
        ax_left.set_ylabel('Value')
        ax_left.tick_params(axis='x', rotation=45)
        
        # Right plot: Feature categories (collapsed) - using text indices to map to feature conditions
        ax_right = axes2[metric_idx, 1]
        
        # For embedding data, we need to map text indices back to feature conditions
        feature_data = []
        
        # High Feature 1 (Paris): F1_high_* conditions
        high_f1_values = []
        high_f1_values.extend(results['F1_high_F2_high'][metric])
        high_f1_values.extend(results['F1_high_F2_low'][metric])
        
        # Low Feature 1 (Paris): F1_low_* conditions  
        low_f1_values = []
        low_f1_values.extend(results['F1_low_F2_high'][metric])
        low_f1_values.extend(results['F1_low_F2_low'][metric])
        
        # High Feature 2 (Folk): *_F2_high conditions
        high_f2_values = []
        high_f2_values.extend(results['F1_high_F2_high'][metric])
        high_f2_values.extend(results['F1_low_F2_high'][metric])
        
        # Low Feature 2 (Folk): *_F2_low conditions
        low_f2_values = []
        low_f2_values.extend(results['F1_high_F2_low'][metric])
        low_f2_values.extend(results['F1_low_F2_low'][metric])
        
        # Add to data
        for val in high_f1_values:
            feature_data.append({'Feature': f'Category 1 ({feature1name})', 'Level': 'High', 'Value': val})
        for val in low_f1_values:
            feature_data.append({'Feature': f'Category 1 ({feature1name})', 'Level': 'Low', 'Value': val})
        for val in high_f2_values:
            feature_data.append({'Feature': f'Category 2 ({feature2name})', 'Level': 'High', 'Value': val})
        for val in low_f2_values:
            feature_data.append({'Feature': f'Category 2 ({feature2name})', 'Level': 'Low', 'Value': val})
        
        df_feature = pd.DataFrame(feature_data)
        
        # Create box plot for feature categories
        sns.boxplot(data=df_feature, x='Feature', y='Value', hue='Level', ax=ax_right)
        ax_right.set_title(f'{title} - Feature Categories')
        ax_right.set_xlabel('Feature')
        ax_right.set_ylabel('Value')
    
    plt.tight_layout()
    
    # Save second plot
    plot2_path = output_path / "nfm_embedding_layer.png"
    plt.savefig(plot2_path, dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"NFM embedding layer plot saved to: {plot2_path}")

def print_summary_statistics(results, feature1_indices, feature2_indices):
    """Print detailed summary statistics for all conditions."""
    
    # Combine all feature indices
    all_feature_indices = list(set(feature1_indices + feature2_indices))
    
    conditions = ['F1_high_F2_high', 'F1_high_F2_low', 'F1_low_F2_high', 'F1_low_F2_low']
    condition_names = ['[1,1] '+feature1name+'+' + feature2name, '[1,0] '+feature1name+'+'+feature2bname, '[0,1] '+feature1bname+'+'+feature2name, '[0,0] '+feature1bname+'+'+feature2bname]
    metrics = ['sae_activations', 'linear_contributions', 'interaction_contributions']
    metric_names = ['SAE Activations', 'Linear Contributions', 'Interaction Contributions']
    
    print("\n" + "="*80)
    print("DETAILED SUMMARY STATISTICS")
    print("="*80)
    
    for metric, metric_name in zip(metrics, metric_names):
        print(f"\n{metric_name}:")
        print("-" * 50)
        
        for cond, cond_name in zip(conditions, condition_names):
            print(f"\n{cond_name}:")
            for feat_idx in all_feature_indices:
                values = results[cond][metric][feat_idx]
                mean_val = np.mean(values)
                std_val = np.std(values)
                min_val = np.min(values)
                max_val = np.max(values)
                
                # Determine which category this feature belongs to
                if feat_idx in feature1_indices:
                    category = f"Cat1 ({feature1name})"
                elif feat_idx in feature2_indices:
                    category = f"Cat2 ({feature2name})"
                else:
                    category = "Both"
                
                print(f"  Feature {feat_idx} [{category}]: "
                      f"{mean_val:.4f} ± {std_val:.4f} "
                      f"(range: {min_val:.4f}-{max_val:.4f})")

def main():
    parser = argparse.ArgumentParser(description="Stimulus-Response Analysis for SAE Features")
    parser.add_argument("--model_path", type=str, required=True, help="Path to base LLM model")
    parser.add_argument("--sae_path", type=str, required=True, help="Path to trained SAE model")
    parser.add_argument("--nfm_path", type=str, required=True, help="Path to trained NFM model")
    parser.add_argument("--output_dir", type=str, default="./stimulus_response_results", 
                        help="Directory to save results")
    parser.add_argument("--batch_size", type=int, default=8, help="Batch size for processing")
    parser.add_argument("--device", type=str, default="cuda", help="Device to use")
    parser.add_argument("--n_features", type=int, default=5, help="Number of top features to discover per category")
    
    args = parser.parse_args()
    
    print("Loading models...")
    
    # Load tokenizer and base model
    tokenizer = AutoTokenizer.from_pretrained(args.model_path)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    base_model = AutoModelForCausalLM.from_pretrained(args.model_path, device_map="auto")
    
    # Load SAE model
    sae_state_dict = torch.load(args.sae_path, map_location=args.device)
    if 'decoder.weight' in sae_state_dict:
        input_dim = sae_state_dict['decoder.weight'].shape[0]
        hidden_dim = sae_state_dict['decoder.weight'].shape[1]
    else:
        encoder_weight = sae_state_dict['encoder.0.weight']
        hidden_dim, input_dim = encoder_weight.shape
    
    sae_model = SparseAutoencoder(input_dim, hidden_dim)
    sae_model.load_state_dict(sae_state_dict)
    sae_model.to(args.device)
    
    # Load NFM model
    nfm_state_dict = torch.load(args.nfm_path, map_location=args.device)
    
    # Infer NFM dimensions
    num_features = nfm_state_dict['feature_embeddings.weight'].shape[0]
    k_dim = nfm_state_dict['feature_embeddings.weight'].shape[1]
    output_dim = nfm_state_dict['linear.weight'].shape[0]
    
    nfm_model = NeuralFactorizationModel(num_features, k_dim, output_dim)
    nfm_model.load_state_dict(nfm_state_dict)
    nfm_model.to(args.device)
    
    # Initialize analyzer
    analyzer = StimulusResponseAnalyzer(sae_model, nfm_model, tokenizer, base_model, args.device)
    
    # FEATURE DISCOVERY PHASE
    feature1_indices, feature2_indices, discovery_stats = analyzer.discover_top_features(
        STIMULUS_SETS, n_features=args.n_features, batch_size=args.batch_size
    )
    
    # Save discovery statistics
    discovery_path = Path(args.output_dir) / "feature_discovery_stats.json"
    discovery_path.parent.mkdir(parents=True, exist_ok=True)
    with open(discovery_path, 'w') as f:
        json.dump(discovery_stats, f, indent=2)
    print(f"\nFeature discovery statistics saved to: {discovery_path}")
    
    # Combine all unique features for analysis
    all_feature_indices = list(set(feature1_indices + feature2_indices))
    
    print(f"\n=== RUNNING FULL ANALYSIS ON {len(all_feature_indices)} DISCOVERED FEATURES ===")
    print(f"Feature 1 indices: {feature1_indices}")
    print(f"Feature 2 indices: {feature2_indices}")
    
    # Store results
    results = {}
    
    # First, collect all SAE activations for K discovery
    all_sae_activations = {}
    all_stimulus_labels = []
    
    # Process each stimulus condition
    for condition_name, texts in STIMULUS_SETS.items():
        print(f"\nProcessing condition: {condition_name}")
        
        # Measure SAE activations
        sae_activations = analyzer.measure_activations(texts, all_feature_indices, args.batch_size)
        
        # Store for K discovery
        for feat_idx in all_feature_indices:
            if feat_idx not in all_sae_activations:
                all_sae_activations[feat_idx] = []
            all_sae_activations[feat_idx].extend(sae_activations[feat_idx])
        
        # Store condition labels
        all_stimulus_labels.extend([condition_name] * len(texts))
        
        # Store in results for later use
        results[condition_name] = {
            'sae_activations': sae_activations
        }
    
    # K DIMENSION DISCOVERY
    k_discovery_stats = analyzer.discover_top_k_dimensions(
        feature1_indices, feature2_indices, all_sae_activations, all_stimulus_labels
    )
    
    # Save K discovery statistics  
    k_discovery_path = Path(args.output_dir) / "k_dimension_discovery_stats.json"
    with open(k_discovery_path, 'w') as f:
        json.dump(k_discovery_stats, f, indent=2)
    print(f"\nK dimension discovery statistics saved to: {k_discovery_path}")
    
    # Now compute NFM contributions with discovered K dimensions
    for condition_name, texts in STIMULUS_SETS.items():
        sae_activations = results[condition_name]['sae_activations']
        
        # Measure NFM contributions with discovered K values
        linear_contributions, interaction_contributions, max_combined_k_embedding, max_diff_k_embedding, max_var_k_embedding, all_k_embedding = analyzer.measure_nfm_contributions(
            sae_activations, all_feature_indices, k_discovery_stats
        )
        
        # Update results
        results[condition_name].update({
            'linear_contributions': linear_contributions,
            'interaction_contributions': interaction_contributions,
            'max_combined_k_embedding': max_combined_k_embedding,
            'max_diff_k_embedding': max_diff_k_embedding,
            'max_var_k_embedding': max_var_k_embedding,
            'all_k_embedding': all_k_embedding
        })
    
    # Print detailed summary statistics
    print_summary_statistics(results, feature1_indices, feature2_indices)
    
    # Create visualization plots
    print("\nCreating analysis plots...")
    create_analysis_plots(results, feature1_indices, feature2_indices, args.output_dir)
    
    # Save detailed results
    results_path = Path(args.output_dir) / "detailed_results.json"
    
    # Convert results to JSON-serializable format
    json_results = {}
    for condition_name, condition_data in results.items():
        json_results[condition_name] = {}
        for metric_name, metric_values in condition_data.items():
            if isinstance(metric_values, dict):
                json_results[condition_name][metric_name] = {str(k): [float(v) for v in val_list]
                                                               for k, val_list in metric_values.items()}
            elif isinstance(metric_values, list):
                json_results[condition_name][metric_name] = [float(v) for v in metric_values]
    
    with open(results_path, 'w') as f:
        json.dump(json_results, f, indent=2)
    
    print(f"\nDetailed results saved to: {results_path}")
    print("Analysis complete!")

if __name__ == "__main__":
    main()